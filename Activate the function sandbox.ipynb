{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activate the function sandbox instead perceptron\n",
    "\n",
    "[ref-url](https://classroom.udacity.com/nanodegrees/nd009-cn-advanced/parts/a3732689-6921-45f8-959a-5078f3814572/modules/74a6a24d-44f4-472e-b17a-8f29cbbf10e9/lessons/7224990821/concepts/72258808312589030923)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------\n",
    "# \n",
    "# Python Neural Networks code originally by Szabo Roland and used with\n",
    "# permission\n",
    "#\n",
    "# Modifications, comments, and exercise breakdowns by Mitchell Owen,\n",
    "# (c) Udacity\n",
    "#\n",
    "# Retrieved originally from http://rolisz.ro/2013/04/18/neural-networks-in-python/\n",
    "#\n",
    "#\n",
    "# Neural Network Sandbox\n",
    "#\n",
    "# Define an activation function activate(), which takes in a number and\n",
    "# returns a number.\n",
    "# Using test run you can see the performance of a neural network running with\n",
    "# that activation function, where the inputs are 8x8 images of digits (0-9) and\n",
    "# the outputs are digit predictions made by the network.\n",
    "#\n",
    "# ----------\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "\n",
    "def activate(strength):\n",
    "    # Try out different functions here. Input strength will be a number, with\n",
    "    # another number as output.\n",
    "    \n",
    "    # sigmoid\n",
    "     return .5*(np.tanh(.5*strength)+1)\n",
    "    \n",
    "    # tanh\n",
    "    # return np.tanh(strength)\n",
    "\n",
    "    #return 1 / (1 + math.exp(-strength))  ×\n",
    "    #Math 这个库，不能接受list ，np.array\n",
    "    #Math 不能处理矩阵 \n",
    "    #Numpy 有广播这个性质\n",
    "    #return 1.0 / (1.0 + np.exp(-strength)) √\n",
    "    \n",
    "    # return np.power(strength,2)\n",
    "    \n",
    "def activation_derivative(activate, strength):\n",
    "    #numerically approximate\n",
    "    return (activate(strength+1e-5)-activate(strength-1e-5))/(2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the result is as follows"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Random snapshot from epoch 542:\n",
    "Our weights [[-0.261271    0.04404007  0.06527019  0.0249699   0.18773238  0.16257585\n",
    "   0.23418254  0.00450345 -0.08569031  0.02847678]\n",
    " [-0.01637136  0.07869034  0.01334717 -0.10785347 -0.12172739  0.17714869\n",
    "  -0.14436172  0.02706065 -0.25797658 -0.06217005]\n",
    " [-0.0850087   0.08532506 -0.02322457 -0.04160237 -0.11779048  0.00200194\n",
    "   0.18776992  0.0141886   0.08722023  0.01198456]\n",
    " [-0.16920652  0.03401511  0.20709163 -0.03126596 -0.02958139 -0.05063059\n",
    "  -0.13838526 -0.01355054  0.12841064  0.01341794]\n",
    " [ 0.04323912 -0.19290812 -0.15368572  0.06776458 -0.20695556  0.09791088\n",
    "  -0.2292303  -0.16883796 -0.05357145 -0.10649192]\n",
    " [-0.17870719 -0.06910466 -0.16662226 -0.0980986  -0.0131074   0.24753028\n",
    "  -0.18616705 -0.14848884  0.0144949   0.04897742]\n",
    " [ 0.15332348 -0.11889353  0.03191907  0.13705444  0.15440639  0.02794524\n",
    "  -0.04476748  0.14544605 -0.02112824 -0.03526791]\n",
    " [ 0.10027594  0.13868546  0.09946904  0.15092267 -0.26210955  0.14825046\n",
    "   0.03036673  0.03762153  0.21052123  0.18091951]\n",
    " [-0.03041646  0.08136164  0.01526965  0.10688235 -0.07909057 -0.15788728\n",
    "  -0.06366019 -0.04718515  0.03147363 -0.12654411]\n",
    " [-0.12185899 -0.12768356  0.08115288 -0.28198814 -0.19179289 -0.2260688\n",
    "   0.02264855 -0.00816788 -0.1526802  -0.19405943]\n",
    " [ 0.24633802 -0.01020369  0.19658815 -0.24120633  0.09670497  0.06486164\n",
    "  -0.02496319 -0.09179346  0.0368254  -0.16359571]\n",
    " [ 0.06397362 -0.09449559 -0.1782871  -0.06554669 -0.08755646  0.02159109\n",
    "   0.14112042  0.0362882   0.00464     0.09040998]\n",
    " [ 0.04980141 -0.10793741  0.0347287   0.01518632  0.10862736 -0.00829203\n",
    "  -0.16694201  0.10006734 -0.00107218 -0.00635321]\n",
    " [-0.01927362  0.10986874 -0.11943437 -0.12024889  0.18859471  0.01531538\n",
    "  -0.16872572  0.14311879  0.17799574 -0.00083708]\n",
    " [ 0.09762249  0.15431477 -0.12013806 -0.0049179   0.07231232 -0.19994579\n",
    "   0.21721241 -0.13613729  0.06531645 -0.14490471]\n",
    " [ 0.24040517 -0.14289753 -0.18305922 -0.15771013 -0.01451672 -0.18444338\n",
    "  -0.05338649 -0.06979262  0.01237786  0.09442503]]\n",
    "\n",
    " are being modified with deltas [[  1.41713006e-01  -1.05233375e-01   2.96593686e-01  -2.62306236e-01\n",
    "   -1.43559228e-01  -8.19721008e-02  -6.84295417e-05   2.21227755e-02\n",
    "   -1.80995162e-01   1.94550873e-01]]\n",
    "\n",
    " using the results matrix [[ 0.54837641 -0.69599363 -0.28859678  0.41635091  0.18757344 -0.31180132\n",
    "   0.05627858  0.39608872  0.49178048  0.0191307   0.72206553 -0.63244446\n",
    "   0.37958091 -0.29723238 -0.16805146 -0.86710158]]\n",
    "\n",
    "Random snapshot from epoch 658:\n",
    "Our weights [[-0.17334446 -0.01746305  0.0723889  -0.06062495  0.07671569  0.02010544\n",
    "   0.14935599  0.12774802 -0.03533081  0.02697346]\n",
    " [ 0.06780068  0.05445713 -0.21338522  0.02917493 -0.07255222  0.09925848\n",
    "  -0.18054342  0.10278494 -0.24138062 -0.23759182]\n",
    " [-0.05835505 -0.00587059 -0.02039631 -0.05512643 -0.00623851 -0.08450686\n",
    "   0.0314508   0.02920166  0.20898683 -0.05151959]\n",
    " [-0.09494308  0.05000563  0.19384858 -0.00672227  0.07599709 -0.14248978\n",
    "  -0.19927259  0.01613586  0.14249978  0.11423352]\n",
    " [-0.06012939 -0.17180587 -0.0345042   0.01354923 -0.31602483  0.04976735\n",
    "  -0.09394459 -0.07769312  0.09883847 -0.05616871]\n",
    " [-0.24330592 -0.06002402 -0.17483396 -0.06116813  0.09675539  0.08207205\n",
    "  -0.09573938 -0.28880912  0.09226596  0.08061007]\n",
    " [ 0.16020607 -0.15694861  0.06500156  0.1225092   0.1527709   0.09429445\n",
    "   0.02815919  0.12893294  0.0579701  -0.0701529 ]\n",
    " [ 0.05744176  0.18111573  0.14482725  0.10131024 -0.24123144  0.15815084\n",
    "  -0.0256679   0.04594267  0.29583281  0.14034461]\n",
    " [-0.09967163  0.06975892  0.08862794  0.05958988 -0.09639137 -0.00426362\n",
    "  -0.04969333 -0.16307899  0.01485314 -0.10416484]\n",
    " [-0.01129769 -0.14119089  0.00299127 -0.22135399 -0.1829628  -0.13347412\n",
    "  -0.09498554  0.09497861 -0.0672474  -0.20030743]\n",
    " [ 0.31787237 -0.02857328  0.34162485 -0.16953405  0.0667909   0.03745321\n",
    "  -0.02488102 -0.17620471  0.06536958 -0.17767443]\n",
    " [ 0.16900567 -0.10305176 -0.27580236 -0.04492484 -0.06203546  0.05627871\n",
    "   0.09062278  0.20781901  0.19951713 -0.07332892]\n",
    " [ 0.13543837 -0.04454291  0.0250991   0.00931962  0.02844549  0.01984351\n",
    "  -0.02366168  0.03552821 -0.12329805  0.12876349]\n",
    " [-0.05351438  0.03271724 -0.237257   -0.01689668  0.22094612  0.10663328\n",
    "  -0.03763967  0.15677465  0.11370352  0.02052002]\n",
    " [ 0.00171056 -0.07035253  0.01686929 -0.01211885  0.09527925 -0.0972635\n",
    "   0.1852049  -0.24319945  0.2199936  -0.1026554 ]\n",
    " [ 0.27161983 -0.05075459 -0.27519687 -0.16652521  0.02929409 -0.05537019\n",
    "  -0.03622121 -0.2453765   0.01549822  0.08936487]]\n",
    "\n",
    " are being modified with deltas [[ 0.12878255 -0.12929357 -0.40106706  0.53132087  0.10076418 -0.09168251\n",
    "  -0.06798365 -0.07373901  0.32312076 -0.00548691]]\n",
    "\n",
    " using the results matrix [[ 0.0777933   0.04992646 -0.37021548 -0.2775043   0.11708472 -0.46991693\n",
    "   0.43340152  0.01234274  0.21917055 -0.48826965 -0.13085489 -0.79959307\n",
    "  -0.03662834 -0.61254755 -0.20589284 -0.66805508]]\n",
    "\n",
    "Random snapshot from epoch 692:\n",
    "Our weights [[-0.07977137 -0.20949336 -0.01028535 ...,  0.12438754 -0.21765403\n",
    "   0.13018533]\n",
    " [-0.1859687   0.14117296 -0.18701488 ..., -0.04431746  0.00428114\n",
    "  -0.18175915]\n",
    " [ 0.20254531  0.05403279 -0.23277248 ..., -0.01192364 -0.19947841\n",
    "  -0.17298458]\n",
    " ..., \n",
    " [-0.16551479 -0.19394173  0.12442616 ...,  0.01613934 -0.16350514\n",
    "  -0.05261278]\n",
    " [-0.19241067  0.13196328  0.21914883 ...,  0.14191155 -0.27375151\n",
    "  -0.17586498]\n",
    " [-0.03995054  0.18877537 -0.23377772 ..., -0.00918251  0.02710457\n",
    "   0.14189644]]\n",
    "\n",
    " are being modified with deltas [[-0.04851274  0.09067164 -0.0337365  -0.04964722  0.01850726  0.01958054\n",
    "   0.05246156 -0.03604001 -0.00851565 -0.0221184   0.07988791  0.0213241\n",
    "   0.04403027  0.00026407  0.01658772  0.07356805]]\n",
    "\n",
    " using the results matrix [[ 0.      0.125   0.8125  0.8125  0.6875  0.5625  0.      0.      0.\n",
    "   0.625   1.      1.      1.      0.9375  0.625   0.      0.      0.6875\n",
    "   1.      0.5625  0.      0.      0.      0.      0.      0.1875  0.9375\n",
    "   1.      0.5     0.      0.      0.      0.      0.      0.125   0.6875\n",
    "   0.875   0.      0.      0.      0.      0.      0.      0.5     1.      0.\n",
    "   0.      0.      0.      0.      0.0625  0.6875  0.6875  0.      0.      0.\n",
    "   0.      0.0625  1.      0.9375  0.25    0.      0.      0.      1.    ]]\n",
    "\n",
    "Random snapshot from epoch 993:\n",
    "Our weights [[-0.07977137 -0.20949336 -0.01028535 ...,  0.12438754 -0.21765403\n",
    "   0.13018533]\n",
    " [-0.19109404  0.14755208 -0.19606872 ..., -0.04356729 -0.00458266\n",
    "  -0.17036397]\n",
    " [ 0.17803849  0.03969658 -0.14999748 ..., -0.04998269 -0.20051128\n",
    "  -0.1412777 ]\n",
    " ..., \n",
    " [-0.11322701 -0.20202034  0.14739828 ...,  0.05105621 -0.20665289\n",
    "  -0.15154071]\n",
    " [-0.17549582  0.11395633  0.22163641 ...,  0.13447347 -0.27921964\n",
    "  -0.19587324]\n",
    " [-0.04296462  0.28725098 -0.23098366 ..., -0.02026872  0.01769049\n",
    "   0.09396824]]\n",
    "\n",
    " are being modified with deltas [[-0.02763815  0.03148713 -0.05966585 -0.02397176  0.01853764  0.04995769\n",
    "   0.03958196 -0.02678368 -0.04410738 -0.03540752  0.00751977 -0.0605794\n",
    "   0.08746614  0.03793679 -0.12608169 -0.03330127]]\n",
    "\n",
    " using the results matrix [[ 0.      0.      0.      0.8125  0.5     0.      0.      0.      0.      0.\n",
    "   0.125   0.9375  0.0625  0.      0.      0.      0.      0.      0.6875\n",
    "   0.625   0.      0.5     0.125   0.      0.      0.25    1.      0.3125\n",
    "   0.6875  1.      0.5     0.      0.      0.4375  1.      1.      1.      1.\n",
    "   0.1875  0.      0.      0.125   0.8125  0.5625  1.      0.75    0.      0.\n",
    "   0.      0.      0.      0.4375  1.      0.375   0.      0.      0.      0.\n",
    "   0.      0.8125  0.9375  0.0625  0.      0.      1.    ]]\n",
    "\n",
    "Confusion matrix: rows indicate true labels, columns indicate predictions.\n",
    "[[46  0  0  0  0  0  8  0  0  0]\n",
    " [ 0  7  1  1  9  1 14  0  9  0]\n",
    " [ 3  0 29  1  0  0  2  0  0  0]\n",
    " [ 0  0  0 41  0  0  2  1  1  0]\n",
    " [ 1  0  0  0 40  0  4  1  2  0]\n",
    " [ 0  0  0  1  2 43  3  0  0  0]\n",
    " [ 0  0  0  0  0  0 42  0  0  0]\n",
    " [ 0  0  0  1  1  0  0 43  0  0]\n",
    " [ 0  0  1  3  1  1 14  0 19  0]\n",
    " [11  0  0  9  6  5  3  2  4 11]]\n",
    "\n",
    "Classification report for above confusion matrix:\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.75      0.85      0.80        54\n",
    "          1       1.00      0.17      0.29        42\n",
    "          2       0.94      0.83      0.88        35\n",
    "          3       0.72      0.91      0.80        45\n",
    "          4       0.68      0.83      0.75        48\n",
    "          5       0.86      0.88      0.87        49\n",
    "          6       0.46      1.00      0.63        42\n",
    "          7       0.91      0.96      0.93        45\n",
    "          8       0.54      0.49      0.51        39\n",
    "          9       1.00      0.22      0.35        51\n",
    "\n",
    "avg / total       0.79      0.71      0.68       450"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
